---
title: "Class 08"
author: "Diego Diaz, PID:A17328629"
format: pdf
toc: true
---

## Background 

In today's class we will apply the methods and techniques clustering and PCA to help make sense of a real world breast cancer fine needle aspiration (FNA) biopsy data set. 

```{r}
fna.data <- read.csv("WisconsinCancer.csv", row.names = 1)
```

Removing the first 'diagnosis' column - I do not want to use this for my machine learning models. We will use it later to compare our results to the expert diagnosis.

```{r}
head(fna.data)
wisc.data <- fna.data[,-1]
head(wisc.data)
dim(wisc.data)
```

>Q1. How many observations are in this dataset?

There are 568 observations in this dataset.

>Q2. How many observations have a malingnant diagnosis?

212 are malignant and 357 are benign. 

```{r}
table(fna.data$diagnosis)
```

>Q3. How many variables/features in the data are suffixed with `_mean`?

10 variables/features are suffixed with "_mean".

```{r}
length(grep("mean", names(wisc.data)))
```

## Performing PCA:

```{r}
#Check column means and standard deviations
colMeans(wisc.data)
apply(wisc.data, 2, sd)
diagnosis <- fna.data$diagnosis
```

```{r}
#Executing PCA
wisc.pr <- prcomp(wisc.data, scale=T)
summary(wisc.pr)
```

>Q4.  From your results, what proportion of the original variance is captured by the first principal component (PC1)?

Around 44% of variance is captured by the first PC.

>Q5. How many principal components (PCs) are required to describe at least 70% of the original variance in the data?

3 PCs are required to describe at least 70% of variance. 

>Q6. How many principal components (PCs) are required to describe at least 90% of the original variance in the data?

7 PCs are required to describe at least 90% of variance. 

## Interperting PCA results:

```{r}
library(ggplot2)
ggplot(wisc.pr$x) +
  aes(PC1, PC2, col=diagnosis) + 
  geom_point()
```

>Q7. What stands out to you about this plot? Is it easy or difficult to understand? Why?

This plot is very difficult to understand, it is plutting individual intergers which end up melding into a black blob on the plot.

```{r}
biplot(wisc.pr)
```

```{r}
ggplot(wisc.pr$x) +
  aes(PC1, PC3, col=diagnosis) +
  geom_point()
```

>Q8. Generate a similar plot for principal components 1 and 3. What do you notice about these plots?

Both of these plots have clear 'lines' of separation of where malignant and benign diagnoses are plotted. 

## Variance Explained: 

Calculating variance of each principal component by squaring the `sdev` component of wisc.pr.

```{r}
pr.var <- wisc.pr$ sdev^2
head(pr.var)
```

Calculating the variance explained by each principal component by dividing by the total variance explained of all principal components. 

```{r}
pve <- pr.var/sum(pr.var)

#Plot variance expained for each principal component
plot(c(1,pve), xlab= "Principal Component",
     ylab = "Proportion of Variance Explained",
     ylim = c(0,1), type="o")
```

Alternative scree plot of the same data, note data driven y-axis:

```{r}
barplot(pve, ylab= "Percent of Variance Explained",
        names.arg=paste0("PC",1:length(pve)), las=2, axes=F)
axis(2, at=pve, labels=round(pve,2)*100)
```

## Communicating PCA results:

Collectively these two plots ("score plot" and "loadings plot") tell us that if a cell's nucleus are deeply indented ("concave") 

> Q9. For the first principal component, what is the component of the loading vector (i.e. wisc.pr$rotation[,1]) for the feature concave.points_mean? This tells us how much this original feature contributes to the first PC. Are there any features with larger contributions than this one?

```{r}
wisc.pr$rotation["concave.points_mean",1]
sort(abs(wisc.pr$rotation[,1]), decreasing = TRUE)[1:10]
```

The loading vector for `concave.points_mean` feature is -0.2608538. There is not a feature that contributes more than the `concave.points_mean`.

## Hierarchical Clustering: 

```{r}
#Scaling the wisc.data using scale() function.
data.scaled <- scale(wisc.data)

#Calculating Euclidean distances between pairs of all observations.
data.dist <-  dist(data.scaled)

#Creating hieracrchical clustering model using complete linkage.
wisc.hclust <- hclust(data.dist, method="complete")
```

>Q10. Using the plot() and abline() functions, what is the height at which the clustering model has 4 clusters?

Height = 20, is the height at which the clustering model has 4 clusters.

```{r}
plot(wisc.hclust)
abline(h=20, col="red", lty=2)
```

```{r}
wisc.hclust.clusters <- cutree(wisc.hclust, h=20)
table(wisc.hclust.clusters, diagnosis)
```

>Q12. Which method gives your favorite results for the same data.dist dataset? Explain your reasoning.

The best method is `ward.D2` since it gives the clearest separation that matches the actual diagnoses. This method also minimized the variance within each cluster. 

## Combining Methods

Here we will take our PCA results and use those as input for clustering, in other words our "wisc.pr$x" scores that we plotted above (the main output from PCA - how the data lie on our new principal component axis/variables) and use a subset of the PCs as input for `hclust()`. 

I want to know how the clustering in `grps` with values of 1 or 2 to correspond with the diagnosis.

```{r}
wisc.pr.hclust <- hclust(dist(wisc.pr$x[,1:3]), method="ward.D2")
grps <- cutree(wisc.pr.hclust, k=2)
plot(wisc.pr.hclust)
table(grps, diagnosis)
```

My clustering group 1 is mostly 'M' diagnoses (188)
, and my clustering group 2 is mostly 'B' (329).

24 FP
179 TP
333 TN
33 FN

Results of new hierarchical clustering model wth the actual diagnoses. 

```{r}
ggplot(wisc.pr$x) +
  aes(PC1, PC2) +
  geom_point(col=grps)
```

> Q13. How well does the newly created hclust model with two clusters separate out the two “M” and “B” diagnoses?

The model is fairly accurate at clustering out the two "M" and "B" diagnoses with few false negatives/positives compared to accurate diagnoses.

```{r}
table(grps, diagnosis)
```

>Q14. How well do the hierarchical clustering models you created in the previous sections (i.e. without first doing PCA) do in terms of separating the diagnoses? Again, use the table() function to compare the output of each model (wisc.hclust.clusters and wisc.pr.hclust.clusters) with the vector containing the actual diagnoses.

As we begin combining clustering models the model becomes much more accurate at outputting accurate diagnoses compared to the actual diagnoses from the data. With `hclust()` and `prcomp()` being the far less accurate than our combined method. 

```{r}
wisc.pr.hclust2 <- hclust(dist(wisc.pr$x[,1:3]), method="ward.D2")
wisc.pr.hclust.clusters <- cutree(wisc.pr.hclust2, k=2)
plot(wisc.pr.hclust2)
table(wisc.pr.hclust.clusters, diagnosis)
```

```{r}
ggplot(wisc.pr$x) +
  aes(PC1, PC2) +
  geom_point(col=wisc.pr.hclust.clusters)
```

## Sensitivity/Specificity:

>Q15. OPTIONAL: Which of your analysis procedures resulted in a clustering model with the best specificity? How about sensitivity?

## Prediction

We will use the `predict()` function that will take our PCA model from before and new cancer cell data and project that data onto our PCA space. 

```{r}
new <- read.csv("new_samples.csv")
npc <- predict(wisc.pr, newdata=new)
plot(wisc.pr$x[,1:2], col=grps)
points(npc[,1], npc[,2], col="blue", pch=16, cex=3)
text(npc[,1], npc[,2], c(1,2), col="white")
```

>Q16. Which of these new patients should we prioritize for follow up based on your results?

We should focus on patient 2 as it this patients falls within our "malignant" diagnosis cluster while patient 2 falls within our "benign" cluster. Since our model is largely accurate we can somewhat rely on it to decide which patient to prioritize.






